{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树（Decision Tree）相关算法\n",
    "\n",
    "### 1 概念\n",
    "\n",
    "决策树是一种树形结构，每个内部节点表示一个属性判断，每条分支代表一个判断结果的输出，每个叶子节点代表一种分类结果。决策树的生成属于监督学习。\n",
    "\n",
    "* 优点：计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可以处理不相关特征数据\n",
    "* 缺点：可能会产生过度匹配问题\n",
    "* 适用数据类型：数值型和标称型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 决策树的构造\n",
    "\n",
    "#### 2.1 使用信息论划分数据集\n",
    "\n",
    "划分数据集的大原则是：将无序的数据变得更加有序。在构造决策树时，我们需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时起决定性作用。因此必须评估每个特征。\n",
    "\n",
    "测试完成后，原始数据集被划分为几个数据子集，它们分布在第一个决策点所有分支上，接着递归划分，直到数据子集内的数据均属于同一类型为止。\n",
    "\n",
    "```\n",
    "# 检测数据集中的每个子项是否属于同一分类：\n",
    "If so return 类标签；\n",
    "Else\n",
    "    寻找划分数据集的最好特征\n",
    "    划分数据集\n",
    "    创建分支节点\n",
    "        for 每个划分的子集\n",
    "            调用函数createBranch并增加返回结果到分支节点中\n",
    "    return 分支节点\n",
    "```\n",
    "\n",
    "#### 2.2 决策树的一般流程\n",
    "\n",
    "1. 收集数据：可以使用任何方法\n",
    "2. 准备数据：决策树构造算法只适用于标称型数据，因此数值型数据必须离散化\n",
    "3. 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期\n",
    "4. 训练算法：构造树的数据结构\n",
    "5. 测试算法：使用经验树计算错误率\n",
    "6. 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 信息增益与熵\n",
    "\n",
    "在划分数据集之前之后信息发生的变化称为信息增益，知道如何计算信息增益，我们就可以\n",
    "计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。\n",
    "\n",
    "熵定义为信息的期望值，在明晰这个概念之前，我们必须知道信息的定义。如果待分类的事\n",
    "务可能划分在多个分类之中，则符号$x_i$的信息定义为\n",
    "\n",
    "<center>$l(x_i) = -log_2p(x_i)$</center>\n",
    "  \n",
    "其中$p(x_i)$是选择该分类的概率。\n",
    "\n",
    "为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值，通过下面的公式得到：\n",
    "  \n",
    "<center>$H = -\\sum_{i=1}^{n}p(x_i)log_2p(x_i)$</center>\n",
    "\n",
    "其中$n$是分类的数目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面编程实现构造决策树（ID3算法）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "'''\n",
    "\n",
    "计算给定数据集的香农熵\n",
    "\n",
    "@param data 待计算数据集\n",
    "\n",
    "'''\n",
    "def calc_shannon_ent(data):\n",
    "    num_entries = len(data)\n",
    "    label_counts = {}\n",
    "    \n",
    "    # 为所有可能分类创建字典\n",
    "    for feat_vec in data:\n",
    "        cur_label = feat_vec[-1]   \n",
    "        if cur_label not in label_counts.keys():\n",
    "            label_counts[cur_label] = 0\n",
    "        label_counts[cur_label] += 1\n",
    "        \n",
    "    # 计算香农熵\n",
    "    shannon_ent = 0.0\n",
    "    for key in label_counts:\n",
    "        prob = float(label_counts[key]) / num_entries\n",
    "        shannon_ent -= prob * log(prob, 2)\n",
    "    return shannon_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "按照给定特征划分数据集\n",
    "\n",
    "@param data 待划分的数据集\n",
    "@param axis 划分数据集的特征\n",
    "@param value 需要返回的特征的值\n",
    "\n",
    "'''\n",
    "\n",
    "def split_data_set(data, axis, value):\n",
    "    ret_data_set = []\n",
    "    for feat_vec in data:\n",
    "        if feat_vec in data:\n",
    "            reduced_feat_vec = feat_vec[:axis]\n",
    "            reduced_feat_vec.extend(feat_vec[axis + 1:])\n",
    "            ret_data_set.append(reduced_feat_vec)\n",
    "    return ret_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "创建数据集\n",
    "\n",
    "'''\n",
    "\n",
    "def create_data_set():\n",
    "    data = [[1, 1, 'yes'],\n",
    "            [1, 1, 'yes'],\n",
    "            [1, 0, 'no'],\n",
    "            [0, 1, 'no'],\n",
    "            [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "选择最好的数据集划分方式\n",
    "\n",
    "@param data 数据集\n",
    "\n",
    "'''\n",
    "\n",
    "def choose_best_split_feature(data):\n",
    "    num_features = len(data[0]) - 1\n",
    "    base_entropy = calc_shannon_ent(data)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = -1\n",
    "    for i in range(num_features):\n",
    "        feat_list = [example[i] for example in data]\n",
    "        unique_vals = set(feat_list)\n",
    "        new_entropy = 0.0\n",
    "        for value in unique_vals:\n",
    "            sub_data_set = split_data_set(data, i, value)\n",
    "            prob = len(sub_data_set) / float(len(data))\n",
    "            new_entropy += prob * calc_shannon_ent(sub_data_set)\n",
    "        info_gain = base_entropy + new_entropy\n",
    "        if info_gain > best_info_gain:            \n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 函数choose_best_split_feature中调用的数据需要满足一定的要求：第一个要求是，数据必须是一种由列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度；第二个要求是，数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "计算出现次数最多的分类名称\n",
    "\n",
    "@param class_list 类别列表\n",
    "\n",
    "'''\n",
    "\n",
    "import operator\n",
    "\n",
    "def majority_cnt(class_list):\n",
    "    class_count={}\n",
    "    for vote in class_list:\n",
    "        if vote not in class_count.keys(): class_count[vote] = 0\n",
    "        class_count[vote] += 1\n",
    "    sorted_class_count = sorted(class_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_class_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "创建决策树\n",
    "\n",
    "@param dataSet 数据集\n",
    "@param labels 标签集\n",
    "\n",
    "'''\n",
    "\n",
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList): \n",
    "        return classList[0]#stop splitting when all of the classes are equal\n",
    "    if len(dataSet[0]) == 1: #stop splitting when there are no more features in dataSet\n",
    "        return majority_cnt(classList)\n",
    "    bestFeat = choose_best_split_feature(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]       #copy all of labels, so trees don't mess up existing labels\n",
    "        myTree[bestFeatLabel][value] = createTree(split_data_set(dataSet, bestFeat, value),subLabels) \n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no'], [1, 'no'], [1, 'no']]\n"
     ]
    }
   ],
   "source": [
    "data, labels = create_data_set()\n",
    "data2 = split_data_set(data, 0, 1)\n",
    "print(data)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_shannon_ent(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_best_split_feature(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = createTree(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: {'flippers': {0: 'no', 1: 'no'}},\n",
       "  1: {'flippers': {0: 'no', 1: 'no'}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
