{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 监督学习\n",
    "\n",
    "### 1 数据预处理技术\n",
    "\n",
    "在真实世界中，经常需要处理大量的原始数据，这些原始数据是机器学习算法无法理解的。\n",
    "为了让机器学习算法理解原始数据，需要对数据进行预处理。\n",
    "\n",
    "#### 1.1 准备工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[3, -1.5, 2, -5.4], [0, 4, -0.3, 2.1], [1, 3.3, -1.9, -4.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3. , -1.5,  2. , -5.4],\n",
       "       [ 0. ,  4. , -0.3,  2.1],\n",
       "       [ 1. ,  3.3, -1.9, -4.3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 详细步骤\n",
    "\n",
    "1. 均值移除（Mean removal），通常把每个特征的平均值移除，以保证特征均值为0，即标准化，消除特征彼此间的偏差（bias）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =\n",
      " [  5.55111512e-17  -1.11022302e-16  -7.40148683e-17  -7.40148683e-17]\n",
      "Std deviation =\n",
      " [ 1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "data_standardized = preprocessing.scale(data)\n",
    "print(\"Mean =\\n\", data_standardized.mean(axis=0))\n",
    "print(\"Std deviation =\\n\", data_standardized.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 范围缩放（Scaling），数据点中每个特征的数值范围可能变化很大，因此，有时将特征的数值范围缩放到合理的大小是非常重要的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min max scaled data =\n",
      " [[ 1.          0.          1.          0.        ]\n",
      " [ 0.          1.          0.41025641  1.        ]\n",
      " [ 0.33333333  0.87272727  0.          0.14666667]]\n"
     ]
    }
   ],
   "source": [
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = data_scaler.fit_transform(data)\n",
    "print(\"Min max scaled data =\\n\", data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 归一化（Normalization），用于需要对特征向量的值进行调整时，以保证每个特征向量的值都缩放到相同的数值范围\n",
    "\n",
    "> 机器学习中最常用的归一化形式就是将特征向量调整为L1范数，使特征向量的数值之和为1\n",
    "\n",
    ">  L0范数表示向量中非0的元素的个数（一般不用）；L1范数表示向量中所有元素的绝对值和（求权值的稀疏矩阵）；L2范数表示欧氏距离（岭回归；防止过拟合）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 normalized data =\n",
      " [[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n"
     ]
    }
   ],
   "source": [
    "data_normalized = preprocessing.normalize(data, norm='l1')\n",
    "print(\"L1 normalized data =\\n\", data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 二值化（Binarization），用于将数值特征向量转换为布尔类型向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized data =\n",
      " [[ 1.  0.  1.  0.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "data_binarized = preprocessing.Binarizer(threshold=1.4).transform(data)\n",
    "print(\"Binarized data =\\n\", data_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 独热编码（One-Hot Encoding），可以把独热编码看作是一种收紧（tighten）特征向量的工具。它把特征向量的每个特征与特征的非重复总数相对应，通过one-of-k的形式对每个值进行编码特征向量的每个特征值都按照这种方式编码，这样可以更加有效地表示空间。\n",
    "\n",
    "> 到目前为止，表示分类变量最常用的方法就是使用one-hot 编码（one-hot-encoding）或N取一编码（one-out-of-N encoding），也叫虚拟变量（dummy variable）。虚拟变量背后的思想是将一个分类变量替换为一个或多个新特征，新特征取值为0和1。对于线性二分类（以及scikit-learn 中其他所有模型）的公式而言，0和1这两个值是有意义的，我们可以像这样对每个类别引入一个新特征，从而表示任意数量的类别。\n",
    "\n",
    "> 比如说，workclass 特征的可能取值包括\"Government Employee\"、\"Private Employee\"、\"Self Employed\" 和\"Self Employed Incorporated\"。为了编码这4个可能的取值，我们创建了4个新特征，分别叫作\"Government Employee\"、\"Private Employee\"、\"SelfEmployed\" 和\"Self Employed Incorporated\"。如果一个人的workclass 取某个值，那么对应的特征取值为1，其他特征均取值为0。因此，对每个数据点来说，4个新特征中只有一个的取值为1。这就是它叫作one-hot编码或N取一编码的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded vector =\n",
      " [[ 0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit([[0, 2, 1, 12], [1, 3, 5, 3], [2, 3, 2, 12], [1, 2, 4, 3]])\n",
    "encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()\n",
    "print(\"Encoded vector =\\n\", encoded_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 标记编码方法\n",
    "\n",
    "在监督学习中，经常需要处理各种各样的标记。这些标记可能是数字，也可能是单词。如果\n",
    "标记是数字，那么算法可以直接使用它们，但是，许多情况下，标记都需要以人们可理解的形式\n",
    "存在，因此，人们通常会用单词标记训练数据集。标记编码就是要把单词标记转换成数值形式，\n",
    "让算法懂得如何操作标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping:\n",
      "audi --> 0\n",
      "bmw --> 1\n",
      "ford --> 2\n",
      "toyota --> 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# 定义一个标记编码器\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# 创建标记\n",
    "input_classes = ['audi', 'ford', 'audi', 'toyota', 'ford', 'bmw']\n",
    "\n",
    "# 为标记编码\n",
    "label_encoder.fit(input_classes)\n",
    "print(\"Class mapping:\")\n",
    "for i, item in enumerate(label_encoder.classes_):\n",
    "    print(item, '-->', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels =\n",
      " ['toyota', 'ford', 'audi']\n",
      "Encoded labels =\n",
      " [3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "# 转换标记\n",
    "labels = ['toyota', 'ford', 'audi']\n",
    "encoded_labels = label_encoder.transform(labels)\n",
    "print(\"Labels =\\n\", labels)\n",
    "print(\"Encoded labels =\\n\", list(encoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels =\n",
      " [2, 1, 0, 3, 1]\n",
      "Decoded labels =\n",
      " ['ford', 'bmw', 'audi', 'toyota', 'bmw']\n"
     ]
    }
   ],
   "source": [
    "# 数字反转回标记内容\n",
    "encoded_labels = [2, 1, 0, 3, 1]\n",
    "decoded_labels = label_encoder.inverse_transform(encoded_labels)\n",
    "print(\"Encoded labels =\\n\", encoded_labels)\n",
    "print(\"Decoded labels =\\n\", list(decoded_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 创建线性回归器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
